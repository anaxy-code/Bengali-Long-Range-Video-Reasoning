{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 145564,
     "status": "ok",
     "timestamp": 1745760227221,
     "user": {
      "displayName": "Enthusiastic Rose",
      "userId": "04182173789866543329"
     },
     "user_tz": -360
    },
    "id": "Xto65OKS2hRa",
    "outputId": "489a1070-fc68-4e1f-e016-ea60c0931624"
   },
   "outputs": [],
   "source": [
    "!pip install chromadb -q\n",
    "!pip install groq -q\n",
    "!pip install langchain -q\n",
    "!pip install langchain_community -q\n",
    "!pip install langchain_google_genai -q\n",
    "!pip install faiss-cpu\n",
    "!pip install -qU langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4516,
     "status": "ok",
     "timestamp": 1745760231733,
     "user": {
      "displayName": "Enthusiastic Rose",
      "userId": "04182173789866543329"
     },
     "user_tz": -360
    },
    "id": "MP4L35IA2DhX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "import time\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 758
    },
    "executionInfo": {
     "elapsed": 1643,
     "status": "ok",
     "timestamp": 1745760233381,
     "user": {
      "displayName": "Enthusiastic Rose",
      "userId": "04182173789866543329"
     },
     "user_tz": -360
    },
    "id": "kfDc7tJ06vDj",
    "outputId": "7b6d2442-7cc8-4887-abe5-7fd423e1f9f1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/content/drive/MyDrive/Long Range Video Question Answering/Original Dataset/Questions_Answer.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1745760233389,
     "user": {
      "displayName": "Enthusiastic Rose",
      "userId": "04182173789866543329"
     },
     "user_tz": -360
    },
    "id": "LzEhjrFZ1vNO"
   },
   "outputs": [],
   "source": [
    "## load the GOOGLE API KEY\n",
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"\"\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "prompt_2 = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    User:\n",
    "    Act as an expert in Bengali MCQ Answer Generation.\n",
    "    Please provide a single-letter answer (0, 1, 2, 3, 4) to the following multiple-choice question,\n",
    "    and your answer must be one of the letters (0, 1, 2, 3, or 4). You must not provide any other\n",
    "    response or explanation.\n",
    "    You are given some language descriptions in Bengali of a first person view video. The video is 3 minute long.\n",
    "    Each sentence describes a 1s clip. Here are the descriptions:\n",
    "    <context>\n",
    "    {context}\n",
    "    <context>\n",
    "    You are going to answer a multiple choice question based on only the descriptions.\n",
    "    Here is the question:\n",
    "    Question:{input}\n",
    "\n",
    "    Assistant:\n",
    "\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1745760233398,
     "user": {
      "displayName": "Enthusiastic Rose",
      "userId": "04182173789866543329"
     },
     "user_tz": -360
    },
    "id": "UaJqO_Xf4zs4"
   },
   "outputs": [],
   "source": [
    "def vector_embedding(content):\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "    # create a document object from a string.\n",
    "    doc = Document(page_content = content)\n",
    "    docs = [doc] #put the document into a list.\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "    final_documents = text_splitter.split_documents(docs)\n",
    "    vectors = FAISS.from_documents(final_documents, embeddings)\n",
    "    return vectors\n",
    "\n",
    "def query_documents(question, vector_store):\n",
    "\n",
    "    document_chain = create_stuff_documents_chain(llm, prompt_2)\n",
    "    retriever = vector_store.as_retriever()\n",
    "    retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "    response = retrieval_chain.invoke({'input': question})\n",
    "\n",
    "    return response\n",
    "\n",
    "def delete_vector_store():\n",
    "    try:\n",
    "        shutil.rmtree(\"./faiss_index\") #faiss creates a folder called faiss_index\n",
    "        print(\"Vector database deleted successfully.\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Vector database not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting vector database: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1588267,
     "status": "ok",
     "timestamp": 1745761821664,
     "user": {
      "displayName": "Enthusiastic Rose",
      "userId": "04182173789866543329"
     },
     "user_tz": -360
    },
    "id": "Vwz-BuG-6PcA",
    "outputId": "5eaaaa83-de8b-4c4f-ac8a-17eca0584b5b"
   },
   "outputs": [],
   "source": [
    "pred = []\n",
    "time_taken = []\n",
    "for _, row in df.iterrows():\n",
    "    start = time.process_time()\n",
    "    content = row['bengali_text']\n",
    "    question = row['question']\n",
    "    options = {\n",
    "        'option 0': row['option 0'],\n",
    "        'option 1': row['option 1'],\n",
    "        'option 2': row['option 2'],\n",
    "        'option 3': row['option 3'],\n",
    "    }\n",
    "\n",
    "    options = [(row['option 0'], row['option 1'], row['option 2'], row['option 3'], row['option 4'])]\n",
    "    vector_store = vector_embedding(content)\n",
    "    print(\"Vector Store DB Is Ready\")\n",
    "\n",
    "    prompt1 = question + \" \" + \"Here are the options:\" + \"\\n\" + str(options)\n",
    "\n",
    "    if prompt1:\n",
    "        response = query_documents(prompt1, vector_store)\n",
    "        print(\"Answer:\", response['answer'])\n",
    "        pred.append(response['answer'])\n",
    "        time_ = time.process_time() - start\n",
    "        print(\"Response time :\", time_)\n",
    "        time_taken.append(time_)\n",
    "        print(\"\\nDocument Similarity Search:\")\n",
    "        for i, doc in enumerate(response[\"context\"]):\n",
    "            print(doc.page_content)\n",
    "            print(\"--------------------------------\")\n",
    "\n",
    "        delete_vector_store() #delete the vector store after the response.\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1745761821721,
     "user": {
      "displayName": "Enthusiastic Rose",
      "userId": "04182173789866543329"
     },
     "user_tz": -360
    },
    "id": "Ksa7UVel8XSj",
    "outputId": "529cd4fe-cbe6-410c-8080-ca8980a415b4"
   },
   "outputs": [],
   "source": [
    "truth = df[['truth']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1745761821733,
     "user": {
      "displayName": "Enthusiastic Rose",
      "userId": "04182173789866543329"
     },
     "user_tz": -360
    },
    "id": "q8TN3BI68emu",
    "outputId": "940c2915-77b9-46ff-be40-191d1e380e7d"
   },
   "outputs": [],
   "source": [
    "sum(1 for x,y in zip(truth,pred) if x == y) / len(truth)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPYHvkF9MDvstlNwLVr0dnv",
   "mount_file_id": "1-LDeve5T94ox_9EnIzeGtJgPLPrSOHdv",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
